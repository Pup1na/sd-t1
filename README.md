# Sistema de AnÃ¡lisis de Calidad de Respuestas - Yahoo! Answers

Este proyecto implementa un sistema distribuido para analizar y comparar la calidad de respuestas generadas por un LLM versus respuestas humanas del dataset de Yahoo! Answers.

## ğŸ—ï¸ Arquitectura del Sistema

El sistema estÃ¡ compuesto por 5 servicios principales:

1. **Traffic Generator**: Simula consultas de usuarios
2. **Cache Service**: Gestiona cache de respuestas frecuentes  
3. **LLM Service**: IntegraciÃ³n con modelo de lenguaje (Gemini)
4. **Score Service**: EvalÃºa calidad de respuestas
5. **Storage Service**: Persistencia de datos

## ğŸš€ ConfiguraciÃ³n Inicial

### Prerequisitos

- Docker y Docker Compose
- Cuenta de Google AI Studio para API de Gemini
- Kaggle CLI (opcional, para dataset completo)

### Paso 1: Clonar y configurar

```bash
git clone <repo-url>
cd Tarea-1-Sistemas-distribuidos
```

### Paso 2: Configurar variables de entorno

```bash
cp .env.example .env
# Editar .env y agregar tu GEMINI_API_KEY
```

### Paso 3: Obtener dataset

**OpciÃ³n A: Dataset completo de Kaggle**
```bash
# Instalar kaggle CLI
pip install kaggle

# Configurar API key en ~/.kaggle/kaggle.json
# Luego ejecutar:
./download_data.sh
```

**OpciÃ³n B: Usar dataset de ejemplo (para pruebas)**
```bash
# Ya incluido en data/sample_data.csv
```

### Paso 4: Inicializar base de datos y cargar datos

```bash
# Levantar solo PostgreSQL
docker-compose up -d postgres

# Cargar datos a la base de datos
docker-compose --profile tools run --rm data_loader

# Verificar carga de datos
docker-compose logs data_loader
```

### Paso 5: Ejecutar el sistema completo

```bash
docker-compose up --build
```

## ğŸ“Š Servicios y Puertos

- **Storage Service**: http://localhost:8001 - API de persistencia y acceso a datos
- **Cache Service**: http://localhost:8002 - GestiÃ³n de cache con Redis
- **Score Service**: http://localhost:8003 - EvaluaciÃ³n de calidad de respuestas
- **LLM Service**: http://localhost:8004 - IntegraciÃ³n con Gemini API
- **Traffic Generator**: http://localhost:8005 - Generador de trÃ¡fico sintÃ©tico
- **PostgreSQL**: localhost:5432 - Base de datos principal
- **Redis**: localhost:6379 - Cache en memoria

## ğŸ”‘ ConfiguraciÃ³n de Gemini API

1. Ir a [Google AI Studio](https://aistudio.google.com/)
2. Crear cuenta y obtener API key
3. Agregar la key al archivo `.env`:
   ```
   GEMINI_API_KEY=tu_api_key_aqui
   ```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ data_loader/         # Carga inicial de datos CSV a BD
â”‚   â”œâ”€â”€ traffic_generator/   # Generador de consultas  
â”‚   â”œâ”€â”€ cache/              # Servicio de cache
â”‚   â”œâ”€â”€ llm_service/        # IntegraciÃ³n LLM
â”‚   â”œâ”€â”€ score_service/      # EvaluaciÃ³n de calidad
â”‚   â””â”€â”€ storage/            # API de persistencia
â”œâ”€â”€ data/                   # Datasets CSV
â”œâ”€â”€ docs/                   # DocumentaciÃ³n
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n
â””â”€â”€ download_data.sh        # Script descarga datos
```

## ğŸ¯ Objetivos Cumplidos

### âœ… Todos los Servicios Implementados
- [x] **Data Loader**: Carga CSV â†’ PostgreSQL con validaciÃ³n
- [x] **Storage Service**: API REST para acceso a datos y estadÃ­sticas  
- [x] **Cache Service**: Redis con polÃ­ticas LRU/LFU/FIFO configurables
- [x] **LLM Service**: IntegraciÃ³n completa con Gemini API
- [x] **Score Service**: EvaluaciÃ³n multi-mÃ©trica (cosine, BLEU, etc.)
- [x] **Traffic Generator**: 4 distribuciones (Poisson, Uniform, Exponential, Normal)
- [x] **Pipeline completo**: End-to-end funcional
- [x] **DockerizaciÃ³n**: Todos los servicios containerizados
- [x] **Script de pruebas**: ValidaciÃ³n automÃ¡tica del sistema

## ğŸ”„ Flujo de Datos Completo

1. **ğŸ“¥ Carga inicial**: `data_loader` â†’ PostgreSQL (10K+ registros)
2. **ğŸ¯ GeneraciÃ³n**: `traffic_generator` â†’ selecciona preguntas de BD
3. **âš¡ Cache**: `cache` â†’ verifica Redis, polÃ­ticas de evicciÃ³n
4. **ğŸ¤– LLM**: `llm_service` â†’ Gemini API para respuestas nuevas
5. **ğŸ“Š Scoring**: `score_service` â†’ evalÃºa calidad multi-mÃ©trica
6. **ğŸ’¾ Storage**: `storage` â†’ persiste resultados y estadÃ­sticas

## ï¿½ Uso del Sistema

### InicializaciÃ³n Completa
```bash
# 1. Configurar variables de entorno
cp .env.example .env
# Agregar GEMINI_API_KEY

# 2. Levantar base de datos
docker-compose up -d postgres

# 3. Cargar datos
docker-compose --profile tools run --rm data_loader

# 4. Iniciar todos los servicios
docker-compose up --build

# 5. Probar el sistema
./test_system.sh
```

### Generar TrÃ¡fico
```bash
# TrÃ¡fico ligero
curl -X POST http://localhost:8005/start-traffic \
  -H "Content-Type: application/json" \
  -d '{"distribution":"uniform","rate":0.5,"duration":60}'

# TrÃ¡fico normal  
curl -X POST http://localhost:8005/start-traffic \
  -H "Content-Type: application/json" \
  -d '{"distribution":"poisson","rate":2.0,"duration":300}'
```

### Monitoreo en Tiempo Real
```bash
# Ver estadÃ­sticas bÃ¡sicas
curl http://localhost:8001/stats  # Storage
curl http://localhost:8002/cache/stats  # Cache
curl http://localhost:8005/stats  # Traffic

# Monitor especializado de cache hits
./monitor_cache.sh  # En terminal separada

# VerificaciÃ³n rÃ¡pida de todos los servicios  
./quick_check.sh
```

## ğŸ“º Logging en Terminal

Cuando ejecutes `docker-compose up`, verÃ¡s logs detallados de:

- **ğŸ“¥ Carga de datos**: Progreso de descarga e importaciÃ³n CSV
- **ğŸ¯ Cache hits/misses**: Cada consulta muestra si fue hit o miss
- **ğŸ† Mejores respuestas**: Resalta respuestas con score > 0.7
- **ğŸš¦ TrÃ¡fico**: Progreso en tiempo real de consultas generadas
- **ğŸ¤– LLM**: Estado de generaciÃ³n de respuestas con Gemini

## ğŸ“š Referencias

- [Dataset Yahoo! Answers](https://www.kaggle.com/datasets/jarupula/yahoo-answers-dataset)
- [Gemini API](https://ai.google.dev/gemini-api/docs)
- [Docker Compose](https://docs.docker.com/compose/)

---

**Entrega 1 - Sistemas Distribuidos 2025-1**
